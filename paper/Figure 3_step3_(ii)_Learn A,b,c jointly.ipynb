{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OHiML5kgJsXx"
   },
   "source": [
    "# Figure 3 (ii) - Learn c, A and b Jointly\n",
    "In this notebook, we test our Deep Inverse Optimization Framework on the task of learning A, b and c jointly\n",
    "\n",
    "This notebook contains three major parts: \n",
    "- I. initialize test instances based on baseline lps generated in *Figure 3_step1_BaselineLP Generation.ipynb*  \n",
    "- II. Experiment (lean A, b and c jointly using deep_inv_opt package)\n",
    "- III. Data Analysis (generating boxplot as Figure 3(ii) in our paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (C) to Yingcong Tan, Andrew Delong, Daria Terekhov. All Rights Reserved.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import deep_inv_opt as io\n",
    "import deep_inv_opt.plot as iop\n",
    "import scipy.optimize as opt\n",
    "import random\n",
    "import torch\n",
    "from scipy.spatial import ConvexHull\n",
    "import os\n",
    "import time\n",
    "\n",
    "# All generated files will be saved in the following directory\n",
    "PATH = \"C:/Users/Public/Downloads/\"\n",
    "\n",
    "def seed_random(seed = 0 ):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "def MSE(x1, x2):\n",
    "    x1 = io.tensor([x1]).view(-1,1)\n",
    "    x2 = io.tensor([x2]).view(-1,1)\n",
    "    err = torch.mean(torch.sum((x1 - x2)**2,0))\n",
    "    \n",
    "    return err.detach().numpy().ravel()\n",
    "\n",
    "def ADG(c,x_predict, x_target):\n",
    "    c_vector = io.tensor(c).view(-1,1)\n",
    "    x_predict = io.tensor(x_predict).view(-1,1)\n",
    "    x_target = io.tensor(x_target).view(-1,1)\n",
    "    err = torch.abs(c_vector.t() @ (x_target - x_predict))\n",
    "    \n",
    "    return err.detach().numpy().ravel()\n",
    "\n",
    "def feasibility(point, A_ub, b_ub, tolerance= 6):\n",
    "    m,n = A_ub.shape\n",
    "    feasibility_ub = np.round(A_ub @ point.reshape((n,1)) - b_ub.reshape((m,1)), tolerance)\n",
    "    if (feasibility_ub <0).all():\n",
    "        return \"feasible\"\n",
    "    elif (feasibility_ub >0).any():\n",
    "        return \"infeasible\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unility Functions\n",
    "- **read_baselineLP**: read A_ub, b_ub and c from baseline LP\n",
    "- **record_corrupt_LP**: record information of corrupt LP (the testing instance for task of learning A, b and c)\n",
    "- **plot_LP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_baselineLP(filename):\n",
    "    lines=[]\n",
    "    \n",
    "    with open(filename, \"rt\") as fp:\n",
    "        for line in fp:\n",
    "            lines.append(line.rstrip('\\n')) \n",
    "\n",
    "    m,n = np.fromstring(lines[0], dtype=int, sep=' ')\n",
    "    \n",
    "    temp = [lines[i+1: i+1+m] for i in range(len(lines)) if \"A_ub\" in lines[i]]\n",
    "    A_ub=np.zeros((m,n))\n",
    "    b_ub=np.zeros((m,1))\n",
    "    for j in range(m):\n",
    "        A_ub[j] = np.fromstring(temp[0][j], dtype=float, sep=' ')\n",
    "    \n",
    "    temp = [lines[i+1: i+1+m] for i in range(len(lines)) if \"b_ub\" in lines[i]]\n",
    "    for j in range(m):\n",
    "        b_ub[j] = np.fromstring(temp[0][j], dtype=float, sep=' ')\n",
    "        \n",
    "    temp = [lines[i] for i in range(len(lines)) if \"vertices\" in lines[i]]\n",
    "    num_vertices = int(temp[0].split()[0])\n",
    "\n",
    "    temp = [lines[i+1: i+1+num_vertices] for i in range(len(lines)) if \"vertices\" in lines[i]]\n",
    "    vertices = np.zeros((num_vertices,n))\n",
    "    for j in range(num_vertices):\n",
    "        vertices[j] = np.fromstring(temp[0][j], dtype=float, sep=' ')\n",
    "\n",
    "    print(vertices)\n",
    "    return A_ub, b_ub, vertices\n",
    "\n",
    "def record_corrupt_LP(filename, data, target_type):\n",
    "    (A_ub, b_ub, c_true, x_true, c_corrupt, x_corrupt) = data\n",
    "\n",
    "    m,n = A_ub.shape\n",
    "    with open(filename, 'w') as LP_file:\n",
    "        # print LP size, m - # constrains, n - # # var        \n",
    "        np.savetxt(LP_file, A_ub.shape, fmt=\"%.d\")\n",
    "        LP_file.write(\"\\n\")\n",
    "\n",
    "        # print LP, Matrix A and b for constraints Ax <= b\n",
    "        LP_file.write(\"A_ub\\n\")\n",
    "        np.savetxt(LP_file, A_ub, fmt=\"%.6f\")\n",
    "        LP_file.write(\"b_ub\\n\")\n",
    "        np.savetxt(LP_file, b_ub, fmt=\"%.6f\")\n",
    "        LP_file.write(\"\\n\")\n",
    "        \n",
    "        LP_file.write(\"c_true\\n\")\n",
    "        np.savetxt(LP_file, c_true.reshape(1,nVar), fmt=\"%.6f\")\n",
    "        LP_file.write(\"x_true\\n\")\n",
    "        np.savetxt(LP_file, x_true.reshape(1,nVar), fmt=\"%.6f\")\n",
    "        LP_file.write(\"\\n\")\n",
    "        \n",
    "        LP_file.write(\"c_corrupt\\n\")\n",
    "        np.savetxt(LP_file, c_corrupt.reshape(1,nVar), fmt=\"%.6f\")\n",
    "        LP_file.write(\"x_corrupt %s\\n\"%target_type)\n",
    "        np.savetxt(LP_file, x_corrupt.reshape(1,nVar), fmt=\"%.6f\")\n",
    "        \n",
    "def plot_LP(filename, ind_lp, vertices, data):\n",
    "    (A_ub, _, c_true, x_true, c_corrupt, x_corrupt) = data\n",
    "\n",
    "    # plot feasible region in 2D\n",
    "    m,n = A_ub.shape\n",
    "    hull = ConvexHull(vertices) \n",
    "    fig = plt.figure(figsize=(5,5), dpi=100)\n",
    "    ax = fig.add_subplot(111)\n",
    "            \n",
    "    for simplex in hull.simplices:\n",
    "        plt.plot(vertices[simplex, 0], vertices[simplex, 1], 'k-')\n",
    "    \n",
    "    x0,y0 = x_true.ravel()\n",
    "    cx,cy = 1.5*(c_true/sum(abs(c_true))).ravel()\n",
    "    ax.arrow(x0,y0 ,cx,cy+0.1, color='b', head_width=0.2, length_includes_head=True)\n",
    "    ax.text(cx + x0, cy +y0, \"c_true\", color='b',fontsize=10)                 \n",
    "    ax.plot(x_true[0], x_true[1], 'bo', label='x_true')\n",
    "                 \n",
    "    x0,y0 = x_corrupt.ravel()\n",
    "    cx,cy = 1.5*(c_corrupt/sum(abs(c_corrupt))).ravel()\n",
    "    ax.arrow(x0,y0 ,cx,cy, color='r', head_width=0.2, length_includes_head=True)  \n",
    "    ax.text(cx + x0, cy +y0+0.1, \"c_corrupt\", color='r',fontsize=10)\n",
    "    ax.plot(x_corrupt[0], x_corrupt[1], 'ro', label='x_corrupt')  \n",
    "    \n",
    "    plt.axis(\"equal\")\n",
    "    plt.xlabel('X1', fontsize=10)\n",
    "    plt.ylabel('X2', fontsize=10)\n",
    "    plt.xlim(-5,5)\n",
    "    plt.ylim(-5,5)\n",
    "    plt.title(\"Corrupted LP %d (n=%d, m=%d)\" % (ind_lp+1, n, m), fontsize =12)    \n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1),\n",
    "          fontsize = 12, ncol=2)\n",
    "    plt.savefig(filename, framon = True,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Generate Test Instances\n",
    "- use the same convexhull as baseline LPs\n",
    "- Generate a random c (which is recorded as c_true, then find its correponding solution (recorded as x_true)  \n",
    "- \"Corrupt\" c_true by adding random noise  \n",
    "- \"Corrupt\" x_true such that:  \n",
    " - it becomes infeasible (i.e., infeasible x_target):  \n",
    " add random noise to x_true, return x_target if it failed the feasiblity test (i.e., (A@x_target-b>0).any())\n",
    " - it becomes feasible (i.e., feasible x_target):  \n",
    " generate random convex combination of all vertices, and ensure the x_true has a relativly large coefficient. (i.e., x_fea = x1*w1+x2*w2+ ... +x_true*w_true, s.t. w1+w2+...+w_true = 1 and w_true = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_3bLP(ind_lp, nVar, nCons, sgima, target_type):\n",
    "    \n",
    "    def randomize_C_Xtarget(A_ub, b_ub):\n",
    "        m,n=A_ub.shape\n",
    "        c = np.random.normal(0,1, n)\n",
    "        c /= sum(abs(c))\n",
    "        c_vector = io.tensor(c).view(-1,1)\n",
    "        A_ub = io.tensor(A_ub)\n",
    "        b_ub = io.tensor(b_ub).view(-1,1)\n",
    "        sol  = io.linprog (c_vector, A_ub, b_ub, max_steps = 200, eps = 1e-7)\n",
    "        if len(sol.size())>0:\n",
    "            return c_vector, sol\n",
    "        \n",
    "    baselineLP = PATH + \"Deep_Inv_Opt/LP baseline/n=%d,m=%d/%svar_LP%s.txt\"%(nVar, nCons, str(nVar).zfill(2),str(ind_lp+1).zfill(2))\n",
    "    A_ub, b_ub, vertices = read_baselineLP(baselineLP)\n",
    "    c_vector, sol = randomize_C_Xtarget(A_ub, b_ub)\n",
    "\n",
    "    if target_type ==\"infeasible\":\n",
    "        flag = False \n",
    "        while flag == False: \n",
    "            x_noise = io.tensor(np.random.uniform(sigma*-1, sigma,(nVar, 1)))\n",
    "            x_corrupt = torch.add(sol, x_noise).numpy()\n",
    "\n",
    "            feaCheck = feasibility(x_corrupt, A_ub, b_ub, tolerance= 5)\n",
    "            if feaCheck == target_type:\n",
    "                flag = True \n",
    "    elif target_type ==\"feasible\":   \n",
    "        dis = np.zeros(len(vertices))\n",
    "        for i in range(len(vertices)):\n",
    "            dis[i] = MSE(vertices[i], sol.detach().numpy())\n",
    "        ind = np.argmin(dis)\n",
    "\n",
    "        a = torch.distributions.Dirichlet(io.tensor([1. for i in range(len(vertices)-1)])).sample((1,)).numpy()\n",
    "        a = np.divide(a,np.sum(a))/10\n",
    "        a = np.insert(a, ind, 0.9)\n",
    "        x_corrupt = (a @ vertices).reshape((nVar, 1))\n",
    "\n",
    "    c_noise = io.tensor(np.random.uniform(sigma*-1, sigma,(nVar, 1)))\n",
    "    c_corrupt = torch.add(c_vector, c_noise).numpy()\n",
    "    \n",
    "    directory = PATH + \"Deep_Inv_Opt/figure3_ii/n=%d,m=%d/\"%(nVar, nCons)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    LP3b = directory + \"%svar_LP%s.txt\"%(str(nVar).zfill(2), str(ind_lp+1).zfill(2))    \n",
    "    data = (A_ub, b_ub, c_vector.detach().numpy(), sol.detach().numpy(),\n",
    "            c_corrupt, x_corrupt)\n",
    "    \n",
    "    record_corrupt_LP(LP3b, data, target_type = target_type)\n",
    "    if nVar <=2:\n",
    "        plot_LP(LP3b[:-3], ind_lp, vertices, data)\n",
    "\n",
    "    return target_type\n",
    "\n",
    "\"\"\" uncomment the following lines to run a quick test of this cell  \"\"\"\n",
    "\n",
    "# print(\"==== Testing \\\"corrupt_lp\\\" ====\")\n",
    "# seed_random()\n",
    "# ind_lp, nVar, nCons, sigma, target_type = 0, 2, 4, 0.2, \"feasible\"\n",
    "# generate_3bLP(ind_lp, nVar, nCons, sigma, target_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the following cell to generate the complete test instanes for Figure 3(ii)\n",
    "\n",
    "#### Pick instance index randomly for two groups: lps with feasible targets and lps with infeasible targets\n",
    "for each class, there are 50 instances (25 for feasible target, 25 for infeasible target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sample_target_type(nVar_range, nCons_range):\n",
    "    for i in range(len(nVar_range)):\n",
    "        for j in range(len(nCons_range[i])):\n",
    "            print(\"%d var, %d cons\" %(nVar_range[i], nCons_range[i][j]))\n",
    "            fea_temp = random.sample(range(num_lp), 25)\n",
    "            infea_temp = [int(i)  for i in range(num_lp) if i not in fea_temp]\n",
    "            fea_temp.sort()\n",
    "            infea_temp.sort()\n",
    "            print(\"\\t\",len(fea_temp),\"feasible points\\n\\tindex\", fea_temp)\n",
    "            print(\"\\t\",len(infea_temp),\"infeasible points\\n\\tindex\", infea_temp)\n",
    "\n",
    "            fea_target.append(fea_temp)\n",
    "            infea_target.append(infea_temp)\n",
    "\n",
    "    #         uncomment to record the index of fea and infea targets\n",
    "    fea_file = PATH + \"Deep_Inv_Opt/figure3_ii/index_fea_infea_targets.txt\"\n",
    "    with open(fea_file, \"w\") as file:\n",
    "        ind = 0\n",
    "        for i in range(len(nVar_range)):\n",
    "            for j in range(len(nCons_range[i])):\n",
    "                file.write(\"%d var, %d cons\\n\" %(nVar_range[i], nCons_range[i][j]))\n",
    "                file.write(\"feasible target\\n\")\n",
    "                np.savetxt(file, np.array(fea_target[ind]).reshape((1, len(fea_target[ind]))), fmt=\"%.d\")\n",
    "                file.write(\"infeasible target\\n\")\n",
    "                np.savetxt(file, np.array(infea_target[ind]).reshape((1, len(infea_target[ind]))), fmt=\"%.d\")\n",
    "                file.write(\"\\n\")\n",
    "                ind+=1\n",
    "\n",
    "fea_target= []\n",
    "infea_target = []  \n",
    "nVar_range = [2, 10]\n",
    "nCons_range = [[4, 8, 16],\n",
    "               [20, 36, 80]]\n",
    "num_lp = 50\n",
    "print(\"==== \\\"sample_target_type\\\" ====\")\n",
    "sample_target_type(nVar_range, nCons_range)\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the following cell to generate the complete test instances for figure 3(ii) based on the instance index randomly selected above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "nVar_range = [2, 10]\n",
    "nCons_range = [[4, 8, 16],\n",
    "               [20, 36, 80]]\n",
    "num_lp = 50\n",
    "sigma = .2\n",
    "\n",
    "seed_random(0)\n",
    "\n",
    "ind = 0\n",
    "for i, nVar in enumerate (nVar_range):\n",
    "    for nCons in nCons_range[i]:\n",
    "        print(\"LPs with %d var and %d cons\"%(nVar, nCons))\n",
    "        for ind_lp in np.arange(num_lp):\n",
    "            if ind_lp in fea_target[ind]:\n",
    "                target_type = \"feasible\"\n",
    "                print(\"\\tind_lp%d, generate feasible target\"%(ind_lp+1))\n",
    "            elif ind_lp in infea_target[ind]:\n",
    "                target_type = \"infeasible\"\n",
    "                print(\"\\tind_lp%d, generate infeasible target\"%(ind_lp+1))\n",
    "            assert target_type == \"feasible\" or target_type == \"infeasible\", \"wrong target_type\"\n",
    "            generate_3bLP(ind_lp, nVar, nCons, sigma, target_type)\n",
    "        \n",
    "        ind+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Experiment - Learn A, b and c jointly using Deep_Inv_Opt Package\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unility Function\n",
    "- **read_3bLP**: read instance data (e.g., x_target, c_inital, etc.)\n",
    "- **read_targettype**: read the target type matrix, for example, fea_ind is a 6*25 matrix which contains the indices of all instances who has a feasible target point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_3bLP(filename):\n",
    "    lines=[]\n",
    "    \n",
    "    with open(filename, \"rt\") as fp:\n",
    "        for line in fp:\n",
    "            lines.append(line.rstrip('\\n')) \n",
    "    # read LP instance\n",
    "    m = int (lines[0])  # num constraints (# rows)\n",
    "    n = int (lines[1])  # num variables (# columns)\n",
    "    \n",
    "    temp = [lines[j+1:j+m+1] for j in range(len(lines)) if \"A_ub\" in lines[j]]\n",
    "    A_ub=np.zeros((m,n))\n",
    "    for i in range(m):\n",
    "        A_ub[i] = np.fromstring(temp[0][i], dtype=float, sep=' ')\n",
    "    \n",
    "    temp = [lines[j+1:j+m+1] for j in range(len(lines)) if \"b_ub\" in lines[j]]\n",
    "    b_ub=np.zeros((m,1))\n",
    "    for i in range(m):\n",
    "        b_ub[i] = np.fromstring(temp[0][i], dtype=float, sep=' ')\n",
    "    \n",
    "    temp = [lines[j+1] for j in range(len(lines)) if \"c_true\" in lines[j]]\n",
    "    \n",
    "    c_true= np.fromstring(temp[0], dtype=float, sep=' ')\n",
    "    \n",
    "    temp = [lines[j+1] for j in range(len(lines)) if \"x_true\" in lines[j]]\n",
    "    x_true= np.fromstring(temp[0], dtype=float, sep=' ')\n",
    "    \n",
    "    temp = [lines[j+1] for j in range(len(lines)) if \"c_corrupt\" in lines[j]]\n",
    "    c_corrupt= np.fromstring(temp[0], dtype=float, sep=' ')\n",
    "    \n",
    "    temp = [lines[j+1] for j in range(len(lines)) if \"x_corrupt\" in lines[j]]\n",
    "    x_corrupt= np.fromstring(temp[0], dtype=float, sep=' ')\n",
    "\n",
    "    return A_ub, b_ub, c_true, x_true, c_corrupt, x_corrupt\n",
    "\n",
    "\n",
    "def read_targettype(filename):\n",
    "    lines=[]\n",
    "    \n",
    "    with open(filename, \"rt\") as fp:\n",
    "        for line in fp:\n",
    "            lines.append(line.rstrip('\\n')) \n",
    "\n",
    "    temp = [lines[j+1] for j in range(len(lines)) if \"feasible target\" in lines[j] and \"infeasible target\" not in lines[j]]\n",
    "    fea_ind=np.zeros((2,3,25))\n",
    "    temp_ind=0\n",
    "    for i in range(2):\n",
    "        for j in range(3):\n",
    "            fea_ind[i,j,:] = np.fromstring(temp[temp_ind], dtype=float, sep=' ')\n",
    "            temp_ind+=1\n",
    "    \n",
    "    temp = [lines[j+1] for j in range(len(lines)) if \"infeasible target\" in lines[j]]\n",
    "    infea_ind=np.zeros((2,3,25))\n",
    "    temp_ind=0\n",
    "    for i in range(2):\n",
    "        for j in range(3):\n",
    "            infea_ind[i,j,:] = np.fromstring(temp[temp_ind], dtype=float, sep=' ')\n",
    "            temp_ind +=1    \n",
    "    \n",
    "    return fea_ind, infea_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sample Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_RANGE_CONS = [[4,  8,  16],\n",
    "               [20, 36, 80]]\n",
    "_RANGE_VAR = [2, 10]\n",
    "_RANGE_MU= [1.5, 5, 10, 20]\n",
    "_RANGE_T0 = [0.5, 1, 5, 10]\n",
    "_RANGE_LR_C = [0.1, 1, 10]\n",
    "_RANGE_LR_Ab = [0.1, 1, 10]\n",
    "_RANGE_EPS = [1e-5]\n",
    "_LOSS_FUNCTION = [\"ADG\",\"MSE\"]\n",
    "_HYPERPARAM = (_RANGE_MU, _RANGE_T0, _RANGE_EPS, _RANGE_LR_C)\n",
    "\n",
    "\n",
    "def sample_hyperparam(filename, num_set = 20, print_hyperparam = True):\n",
    "    hyperParam = [[]]*num_set\n",
    "    for i in range(20):\n",
    "        mu = _RANGE_MU[np.random.randint(0, len(_RANGE_MU))]\n",
    "        t0 = _RANGE_T0[np.random.randint(0, len(_RANGE_T0))]\n",
    "        eps = _RANGE_EPS[np.random.randint(0, len(_RANGE_EPS))]\n",
    "        lr_c = _RANGE_LR_C[np.random.randint(0, len(_RANGE_LR_C))]\n",
    "        lr_Ab = _RANGE_LR_Ab[np.random.randint(0, len(_RANGE_LR_Ab))]\n",
    "        hyperParam[i] = (mu, t0, eps, lr_c, lr_Ab)\n",
    "        if print_hyperparam:\n",
    "            print(\"hyperparam set %d\"%(i))\n",
    "            print(hyperParam[i])\n",
    "        with open(filename, 'w') as file:\n",
    "            for j in range(len(hyperParam)):\n",
    "                file.write(\"hyperParam%s: \"%(str(j+1).zfill(2)))\n",
    "                np.savetxt(file, np.mat(hyperParam[j]).ravel(), fmt='%.6f')\n",
    "            file.write(\"\\n\")\n",
    "            \n",
    "\n",
    "def read_hyperParam(filename):\n",
    "    with open(filename, 'rt') as file:\n",
    "        lines=file.readlines()\n",
    "        temp = [lines[i] for i in range(len(lines)) if \"hyperParam\" in lines[i]]\n",
    "#         hyperParam = np.zeros((20,4))\n",
    "        hyperParam = [[]]*20\n",
    "        for i in range(len(temp)):\n",
    "            te = temp[i]\n",
    "            te = te[14:]\n",
    "            te = te[:-2]\n",
    "            te = te.split(' ')\n",
    "            hyperParam[i] = [float(j) for j in te]\n",
    "    return hyperParam\n",
    "\n",
    "print(\"==== Sample Hyperparameters values for Random Hyperparameter Search====\")\n",
    "seed_random()\n",
    "filename = PATH + 'Deep_Inv_Opt/figure3_ii/Hyper_Param.txt'\n",
    "sample_hyperparam(filename)\n",
    "read_hyperParam(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment\n",
    "#### Please Note, finishing the entire experiments (i.e., 6 * 50 instances for Training with ADG and MSE) might take 1-2 days. You may see our paper for the experiment results directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_randomsearch(ind_lp, LPInstance, hyperParam, target_type):\n",
    "    def record_result(filename, hyperpara, result):\n",
    "        loss, time, c_final, x_final = result\n",
    "        with open(filename, 'a') as file:\n",
    "            mu, t0, eps, lr_c, lr_Ab = hyperParam[ind_search]\n",
    "            temp = (mu, t0, eps, lr_c, lr_Ab, l, t)\n",
    "            string = (\"hyperparam\"+str(ind_search+1).zfill(2)+\" \"+ str(temp) )\n",
    "            file.write(str(string))\n",
    "            file.write(\"\\n\")\n",
    "            file.write(\"c_final \")\n",
    "            np.savetxt(file, c.reshape(1,nVar), fmt='%.6f') \n",
    "            file.write(\"x_final \")\n",
    "            np.savetxt(file, x.reshape(1,nVar), fmt='%.6f')    \n",
    "        \n",
    "    # initialize LP instance\n",
    "    A_ub, b_ub, _, _, c_corrupt, x_corrupt = LPInstance\n",
    "    \n",
    "    nCons,nVar = A_ub.shape\n",
    "    A_ub = io.tensor(A_ub)\n",
    "    b_ub = io.tensor(b_ub).view(-1,1)  \n",
    "    c_init = io.tensor(c_corrupt).view(-1,1)\n",
    "    x_target = io.tensor(x_corrupt).view(-1,1)  \n",
    "\n",
    "    print(\"||||| Ins %d (%d var, %d constraint)\"\n",
    "          %(ind_lp+1, nVar, nCons))\n",
    "    print(\"||||| \",target_type, \"target: \", x_target.detach().numpy().ravel())\n",
    "    \n",
    "    for loss in [\"ADG\",\"MSE\"]:   \n",
    "        \n",
    "        # record LP characteristics\n",
    "        _RESULT_FILE = PATH + 'Deep_Inv_Opt/figure3_ii/EXP_%svar_%scon_%s.txt'%(str(nVar).zfill(2),str(nCons).zfill(2), loss)\n",
    "        with open(_RESULT_FILE, 'a') as file:\n",
    "            file.write( \"LP%s, %svar %scon:\\n\"\n",
    "                       %(str(ind_lp+1).zfill(2),str(nVar).zfill(2),str(nCons).zfill(2)))\n",
    "            file.write( \"x_target %s\\n\"%target_type ) \n",
    "            np.savetxt(file, x_target.detach().numpy().reshape(1,nVar), fmt='%.6f')\n",
    "            file.write(\"c_init: \")\n",
    "            np.savetxt(file, c_init.numpy().reshape(1,nVar), fmt='%.6f')\n",
    "                        \n",
    "        # initialize loss function\n",
    "        if loss ==\"ADG\":\n",
    "            loss_callback = io.abs_duality_gap\n",
    "            eps_decay = False\n",
    "        elif loss ==\"MSE\":\n",
    "            loss_callback = io.squared_error \n",
    "            eps_decay = True\n",
    "        \n",
    "        callback = None\n",
    "\n",
    "        for ind_search in range(len(hyperParam)):\n",
    "            # initialize hyper parameters\n",
    "            mu, t0, eps, lr_c, lr_Ab = hyperParam[ind_search]\n",
    "            print(\"loss func %s, HyperParam %d = (%.1f, %.1f, %.5f, %.1f, %.4f)\"\n",
    "                  %(loss, ind_search+1, mu, t0, eps, lr_c, lr_Ab))\n",
    "            print(\"---- c_init \", c_init.numpy().ravel())\n",
    "            print(\"---- EXP %d / %d: \"%(ind_search+1, len(hyperParam)))\n",
    "            start_time = time.time()\n",
    "            \n",
    "            solver = io.custom_linprog(t0 = t0, mu = mu, max_steps = 10000)\n",
    "\n",
    "                \n",
    "            try:\n",
    "                c_final, _, _, err, x_predict, init_err = io.inverse_linprog(x_target, \n",
    "                                                            c_init,  A_ub, b_ub,\n",
    "                                                            max_steps=200,\n",
    "                                                            eps = eps, \n",
    "                                                            eps_decay = eps_decay,\n",
    "                                                            learn_rate_c=lr_c,\n",
    "                                                            learn_rate_ub = lr_Ab,\n",
    "                                                            loss=loss_callback,\n",
    "                                                            return_loss=True,\n",
    "                                                            solver=solver)\n",
    "                runtime = time.time() - start_time\n",
    "\n",
    "                c = c_final.detach().numpy().ravel()\n",
    "                x = x_predict.detach().numpy().ravel()\n",
    "                l = err.detach().numpy().ravel()\n",
    "                t = runtime\n",
    "\n",
    "                print(\"---- Final loss\", l)\n",
    "\n",
    "                result = (l[0], t, c, x)\n",
    "                record_result(_RESULT_FILE, hyperParam[ind_search], result)   \n",
    "\n",
    "\n",
    "            except:# catch error and return failed hyperparam search\n",
    "                print(\"find an error, return failed hyperparam search\")\n",
    "                c = np.ones((c_corrupt.shape))*999\n",
    "                x = np.ones((c_corrupt.shape))*999\n",
    "                l = 999\n",
    "                t = 999                \n",
    "                \n",
    "                result = (l, t, c, x)\n",
    "                record_result(_RESULT_FILE, hyperParam[ind_search], result)   \n",
    "                           \n",
    "                pass\n",
    "\n",
    "        print()\n",
    "\n",
    "\n",
    "_RANGE_CONS = [[4,  8,  16],\n",
    "               [20, 36, 80]]\n",
    "_RANGE_VAR = [2, 10]\n",
    "\n",
    "NUM_INS = 50\n",
    "fea_ind, infea_ind = read_targettype(PATH + \"Deep_Inv_Opt/figure3_ii/index_fea_infea_targets.txt\")\n",
    "\n",
    "for i, nVar in enumerate(_RANGE_VAR):\n",
    "    for j, nCons in enumerate(_RANGE_CONS[i]):\n",
    "        for ind_lp in range(NUM_INS):\n",
    "            filename = PATH + \"Deep_Inv_Opt/figure3_ii/n=%d,m=%d/%svar_LP%s.txt\"%(nVar, nCons, str(nVar).zfill(2),str(ind_lp+1).zfill(2))\n",
    "            LPInstance = read_3bLP(filename)\n",
    "            \n",
    "            if ind_lp in fea_ind[i,j,:]:\n",
    "                target_type = \"feasible\"\n",
    "            elif ind_lp in infea_ind[i,j,:]:\n",
    "                target_type = \"infeasible\"\n",
    "            assert target_type == \"feasible\" or target_type == \"infeasible\", \"wrong target_type\"\n",
    "\n",
    "            hyperParam = read_hyperParam(PATH + 'Deep_Inv_Opt/figure3_ii/Hyper_Param.txt')\n",
    "            exp_randomsearch(ind_lp, LPInstance, hyperParam, target_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Data Analysis\n",
    "\n",
    "### Unility Function\n",
    "- **read_finalresult**: read result from data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_finalresult(num_lp, nCons, nVar, loss):\n",
    "    \n",
    "    print(\"loss = \", loss)\n",
    "    c_init = np.zeros((num_lp, nVar))\n",
    "\n",
    "    # read c_init and LP ins\n",
    "    for ind_lp in range(num_lp):\n",
    "        filename = PATH + \"Deep_Inv_Opt/figure3_ii/n=%d,m=%d/%svar_LP%s.txt\"%(nVar, nCons, str(nVar).zfill(2),str(ind_lp+1).zfill(2))\n",
    "#         A, b, opt_sol, c = LP_ins(filename)\n",
    "        A,b,_,_,c_corrupt,x_corrupt = read_3bLP(filename) #new read function for 3b ins generted using idea 5\n",
    "\n",
    "        c_init[ind_lp] = c_corrupt\n",
    "\n",
    "    # read x_target\n",
    "    x_target = np.zeros((num_lp, nVar))\n",
    "    result = []\n",
    "    c_final = []\n",
    "    x_final = []\n",
    "\n",
    "    with open(PATH + 'Deep_Inv_Opt/figure3_ii/FinalExp _%svar_%scon_%s.txt'\n",
    "              %(str(nVar).zfill(2),str(nCons).zfill(2), loss), 'rt') as file:\n",
    "        lines=file.readlines()\n",
    "#         temp = [lines[i+1] for i in range(len(lines)) if \"Vertex\" in lines[i]]\n",
    "    temp = [lines[i+1] for i in range(len(lines)) if \"x_target\" in lines[i]]\n",
    "\n",
    "    for i in range(num_lp):\n",
    "        te =temp[i]\n",
    "        te = te.split(' ')\n",
    "        te = [float(d) for d in te]\n",
    "#             print(te)\n",
    "        x_target[i] = te\n",
    "#     print(\"x_target\\n\",x_target)\n",
    "\n",
    "    #read exp results of every trail (mu, to, eps, lr_c, err, runtime)\n",
    "    temp = [lines[i] for i in range(len(lines)) if \"hyperparam\" in lines[i]]\n",
    "#         hyperParam = np.zeros((20,4))\n",
    "    for i in range(len(temp)):\n",
    "        te = temp[i]\n",
    "        te = te[14:]\n",
    "        te = te[:-2]\n",
    "\n",
    "        te = te.split(',')\n",
    "        te = [float(d) for d in te]\n",
    "        result.append(te)\n",
    "    result= np.mat(result)\n",
    "#             print(result.shape)\n",
    "    #from result find the index of the best trail for each LP ins\n",
    "    best_ind = []\n",
    "    for i in range(num_lp):\n",
    "        best_ind.append(int ( i*20 + np.argmin(result[i*20:(i+1)*20,-2])))\n",
    "    best_ind = np.array(best_ind)\n",
    "#         print(best_ind)\n",
    "\n",
    "\n",
    "    # read c_final for every trail\n",
    "    temp = [lines[i] for i in range(len(lines)) if \"c_final\" in lines[i]]\n",
    "#         hyperParam = np.zeros((20,4))\n",
    "    for i in range(len(temp)):\n",
    "        te = temp[i]\n",
    "        te = te[8:]                \n",
    "        te = te.split(' ')\n",
    "        te = [float(d) for d in te]\n",
    "        c_final.append(te)\n",
    "    c_final= np.mat(c_final)\n",
    "#         print(c_final)\n",
    "\n",
    "    # read x_final for every trail\n",
    "    temp = [lines[i] for i in range(len(lines)) if \"x_final\" in lines[i]]\n",
    "#     print(temp)\n",
    "    #         hyperParam = np.zeros((20,4))\n",
    "    for i in range(len(temp)):\n",
    "        te = temp[i]\n",
    "        te = te[8:]                \n",
    "        te = te.split(' ')\n",
    "        te = [float(d) for d in te]\n",
    "        x_final.append(te)\n",
    "    x_final= np.mat(x_final)\n",
    "#         print(x_final)\n",
    "#             print(result[best_ind, -2])\n",
    "    return result, c_init, c_final, best_ind, x_target, x_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect experiment results using the read_finalresult function\n",
    "- collect final error (using ADG and MSE functions defined before)\n",
    "- collect initial c and x to computer initial error (using ADG and MSE functions defined before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Collect_Err(num_lp,  nVar, num_constraints, loss):\n",
    "    err_final = np.zeros((num_lp,len(num_constraints)))\n",
    "    err_init = np.zeros((num_lp, len(num_constraints)))\n",
    "    fea_ind = [[]]*3\n",
    "    infea_ind = [[]]*3\n",
    "    for j,nCons in enumerate (num_constraints): \n",
    "        print(\"LPs with %dVar, %dCons\"%(nVar,nCons))\n",
    "        result, c_init, c_final, best_ind, x_target, x_final = read_finalresult (num_lp, nCons, nVar, loss)\n",
    "#         print(x_target)\n",
    "        err = result[best_ind,-2]\n",
    "        err_final[:,j] = np.array(err).ravel()\n",
    "#         print(err, err_final)\n",
    "        \n",
    "        fea_temp=[]\n",
    "        infea_temp=[]\n",
    "        for ind_lp in range(num_lp):\n",
    "            filename = PATH + \"Deep_Inv_Opt/figure3_ii/n=%d,m=%d/%svar_LP%s.txt\"%(nVar, nCons, str(nVar).zfill(2),str(ind_lp+1).zfill(2))\n",
    "            A,b,_,_,_,_ = read_3bLP(filename)\n",
    "#             A, b, _, _ = LP_ins(filename)\n",
    "            if feasibility(x_target[ind_lp], A, b) == \"feasible\":\n",
    "#                 print(\"ins\",ind_lp, \"has fea target\")\n",
    "                fea_temp.append(ind_lp)\n",
    "            if feasibility(x_target[ind_lp], A, b) == \"infeasible\":\n",
    "                infea_temp.append(ind_lp)\n",
    "            A_ub = io.tensor(A)\n",
    "            b_ub = io.tensor(b).view(-1,1)\n",
    "            # c_init is not normalized\n",
    "            c_vector = io.tensor(c_init[ind_lp]).view(-1,1)\n",
    "            c_vector/=sum(abs(c_vector))\n",
    "            \n",
    "            x_predict = io.linprog(c_vector, A_ub, b_ub, eps = 1e-6).detach().numpy()\n",
    "            if loss == \"ADG\":            \n",
    "                err_init[ind_lp, j] = ADG( c_vector.detach().numpy(), x_predict, x_target[ind_lp])\n",
    "            elif loss == \"MSE\":            \n",
    "                err_init[ind_lp, j] = MSE(x_predict, x_target[ind_lp])\n",
    "            #             print(\"recompute init error\", err_init[ind_lp], \"final error\",err[ind_lp])\n",
    "        \n",
    "        fea_ind[j] = fea_temp\n",
    "        print(\"index of lp with fea target\",fea_temp)\n",
    "        infea_ind[j] = infea_temp\n",
    "        print(\"index of lp with infea target\",infea_temp)\n",
    "\n",
    "        print(\"%d fea target, %d infea target\"%(len(fea_temp),len(infea_temp)))\n",
    "#     err_final = np.array(err_final).ravel()\n",
    "#     err_init =np.array(err_init).ravel()\n",
    "    return err_init, err_final, fea_ind,  infea_ind\n",
    "\n",
    "\n",
    "num_lp = 50\n",
    "var_range = [2,10]\n",
    "cons_range = [[4, 8, 16],\n",
    "             [20,36,80]]\n",
    "\n",
    "ADG02_init, ADG02_final, fea02_ind,  infea02_ind = Collect_Err(num_lp, 2, cons_range[0], \"ADG\")\n",
    "\n",
    "ADG10_init, ADG10_final, fea10_ind,  infea10_ind = Collect_Err(num_lp, 10, cons_range[1], \"ADG\")\n",
    "\n",
    "MSE02_init, MSE02_final, fea02_ind,  infea02_ind = Collect_Err(num_lp, 2, cons_range[0], \"MSE\")\n",
    "\n",
    "MSE10_init, MSE10_final, fea10_ind,  infea10_ind = Collect_Err(num_lp, 10, cons_range[1], \"MSE\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create boxplot using the collected data from the previous cell\n",
    "\n",
    "**Note, the final boxplots might not look identical to what we presented in the paper due to the randomization in baseline LP generation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADG_ERR = (ADG02_init, ADG02_final, ADG10_init, ADG10_final )\n",
    "MSE_ERR = (MSE02_init, MSE02_final, MSE10_init, MSE10_final)\n",
    "\n",
    "target_ind = (fea02_ind,  infea02_ind, fea10_ind,  infea10_ind )\n",
    "\n",
    "def final_plot(err_data, target_ind):\n",
    "    init02, final02, init10, final10 = err_data\n",
    "    fea02_ind,  infea02_ind, fea10_ind,  infea10_ind = target_ind\n",
    "\n",
    "\n",
    "    fea=[]\n",
    "    for ind in (fea02_ind, fea10_ind):\n",
    "        for i in range(len(ind)):\n",
    "            fea.append(ind[i])\n",
    "    infea=[]\n",
    "    for ind in (infea02_ind, infea10_ind):\n",
    "        for i in range(len(ind)):\n",
    "            infea.append(ind[i])\n",
    "\n",
    "    data02 = init02\n",
    "    for i in range(3):\n",
    "        data02 = np.insert(data02, i*2+1, final02[:,i], axis=1)\n",
    "    data10 = init10\n",
    "    for i in range(3):\n",
    "        data10 = np.insert(data10, i*2+1, final10[:,i], axis=1)\n",
    "\n",
    "    data_ = np.column_stack((data02,data10))\n",
    "    data_ [data_<1e-10]=1e-10\n",
    "\n",
    "    return fea, infea, data_\n",
    "\n",
    "\n",
    "for _LOSS in [\"MSE\", \"ADG\"]:\n",
    "\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    if _LOSS == \"ADG\":\n",
    "        fea, infea, data = final_plot(ADG_ERR, target_ind)\n",
    "        data [data<1e-8]=1e-8\n",
    "        plt.ylim((1e-9,1e2))\n",
    "        print(np.array(fea).shape)\n",
    "    elif _LOSS == \"MSE\":\n",
    "        fea, infea, data = final_plot(MSE_ERR, target_ind)\n",
    "        data [data<1e-10]=1e-10\n",
    "        plt.ylim((1e-11,1e2))\n",
    "        print(np.array(fea).shape)\n",
    "\n",
    "    _, nbox = data.shape    \n",
    "\n",
    "    ind_init = np.arange(0,nbox,2)\n",
    "    ind_final = np.arange(1,nbox,2)\n",
    "\n",
    "    y_init = data[:, ind_init]\n",
    "    x_init = np.random.uniform(1-.15, 1+0.15, size=len(data[:, ind_init]))\n",
    "    y_final = data[:, ind_final]\n",
    "    x_final = np.random.uniform(2-.15, 2+0.15, size=len(data[:, ind_final]))\n",
    "    for i in np.arange(2, nbox,2):\n",
    "        min = i+1-0.15\n",
    "        max = i+1+0.15\n",
    "        x_init = np.column_stack((x_init, np.random.uniform(i+1-.15, i+1+0.15, \n",
    "                                                            size=len(data[:, i]))))\n",
    "    for i in np.arange(3, nbox,2):\n",
    "        min = i+1-0.15\n",
    "        max = i+1+0.15\n",
    "        x_final = np.column_stack((x_final, np.random.uniform(i+1-.15, i+1+0.15, \n",
    "                                                              size=len(data[:, i]))))\n",
    "    ax.boxplot(data,sym='',medianprops =dict(linewidth=1,color='black'))\n",
    "\n",
    "    for i in range(nbox//2):\n",
    "        ax.plot(x_init[fea[i], i], y_init[fea[i], i], \n",
    "                ls='None',mec = 'g', marker=\"+\", mew= 1, markersize=11, alpha=0.5) \n",
    "        ax.plot(x_init[infea[i], i], y_init[infea[i], i], \n",
    "                ls='None',mec = 'g', marker=\"x\", mew= 1, markersize=9,alpha=0.5) \n",
    "\n",
    "    for i in range(nbox//2):\n",
    "        ax.plot(x_final[fea[i], i], y_final[fea[i], i], \n",
    "               ls='None',mec = 'b', marker=\"+\", mew= 1, markersize=11, alpha=0.5) \n",
    "        ax.plot(x_final[infea[i], i], y_final[infea[i], i], \n",
    "               ls='None',mec = 'b', marker=\"x\", mew= 1, markersize=9, alpha=0.5) \n",
    "    \n",
    "    plt.xticks([], [])\n",
    "    plt.yscale(\"log\")\n",
    "    plt.yticks(fontsize=12)\n",
    "\n",
    "    plt.savefig(PATH + \"Deep_Inv_Opt/deepinverse_fig3_ii_%s.pdf\"%_LOSS, frameon = True, bbox_inches='tight', dpi=100)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "FINAL_EXP-3b_Generate_Corrupted_LPs.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
