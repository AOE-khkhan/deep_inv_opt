{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to generate Figure 1 from the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (C) to Yingcong Tan, Andrew Delong, Daria Terekhov. All Rights Reserved.\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rcParams['figure.max_open_warning'] = 0\n",
    "%matplotlib inline\n",
    "import deep_inv_opt as io\n",
    "import deep_inv_opt.plot as iop\n",
    "\n",
    "as_tensor = io.as_tensor\n",
    "as_numpy = io.as_numpy\n",
    "as_str = io.as_str\n",
    "\n",
    "# to save the figure images to disk, override this with something like \"~/Downloads\"  \n",
    "FIGURE_SAVE_DIR = \"C:/Users/Public/Downloads/\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 1A \"learn c only\"\n",
    "This sub-figure depicts a classical inverse optimization problem: infer the *c* vector from a single observation `x_train`. There are closed form solutions to this in terms of the constraint coefficients, but we can also learn a good c vector by gradient descent on a squared error loss. Even though we are using the ParametricLP machinery to encode the c-vector with a single coefficient `w0`, that is just to make the example tidier -- it is not really a parametric LP being inversely optimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Figure1A_PLP(io.ParametricLP):\n",
    "    \n",
    "    def generate(self, u, w):\n",
    "        (w0,) = w\n",
    "        \n",
    "        c = [[torch.cos(w0)],\n",
    "             [torch.sin(w0)]]\n",
    "\n",
    "        A_ub = [[-1.0,  0.0],  # x0 >= 0\n",
    "                [ 0.0, -1.0],  # x1 >= 0\n",
    "                [ 1.0,  0.0],  # x0 <= 1\n",
    "                [ 0.0,  1.0],  # x1 <= 1\n",
    "                [ 1.0,  1.5]]  # x0 + x1 <= ...\n",
    "\n",
    "        b_ub = [[ 0.0 ],\n",
    "                [ 0.0 ],\n",
    "                [ 1.0 ],\n",
    "                [ 0.75 ],\n",
    "                [ 1.5]]\n",
    "        \n",
    "        return c, A_ub, b_ub, None, None\n",
    "    \n",
    "    def __call__(self, u=None):\n",
    "        if u is None:\n",
    "            u = as_tensor([[0.0]])  # Dummy u, not used\n",
    "        return super().__call__(u)\n",
    "    \n",
    "    def plot(self, color='k', fig=None, linestyle=None, want_constraints=True):\n",
    "        with torch.no_grad():\n",
    "            # Set up the plot\n",
    "            if fig is None:\n",
    "                fig = plt.figure(dpi=100, figsize=(5, 5))\n",
    "                ax = fig.add_subplot(111)\n",
    "                ax.set_xlim(-0.35, 1.25)\n",
    "                ax.set_ylim(-0.35, 1.25)\n",
    "                \n",
    "                ax.set_aspect('equal', 'box')\n",
    "                ax.set_axis_off()\n",
    "                fig.tight_layout()\n",
    "            else:\n",
    "                ax = fig.gca()\n",
    "\n",
    "            # Plot each set of constraints\n",
    "            c, A_ub, b_ub, _, _ = as_numpy(*self())            \n",
    "            iop.plot_linear_program(0.25*c,\n",
    "                                    A_ub if want_constraints else None,\n",
    "                                    b_ub if want_constraints else None,\n",
    "                                    color=color, linestyle=linestyle, cxy=(0.85, 1.0))\n",
    "            return fig, ax\n",
    "            \n",
    "\n",
    "##########################################\n",
    "        \n",
    "f_true  = Figure1A_PLP([np.pi*6/4+0.08])  # True c angle\n",
    "f_learn = Figure1A_PLP([3.8])\n",
    "\n",
    "u_train = io.tensor([[0.0]])\n",
    "x_train = torch.cat([io.linprog(*f_true(), eps=0.0000001).detach().t() for ui in u_train])\n",
    "\n",
    "# Plot c_true and constraints\n",
    "fig, ax = f_true.plot(color='k')\n",
    "iop.plot_targets(x_train, 'ok', markerfacecolor='white', markersize=14.0, markeredgewidth=1.5)\n",
    "\n",
    "# Plot c_init\n",
    "f_learn.plot(color=[0.1, 0.7, 0.0], fig=fig, want_constraints=False)\n",
    "iop.plot_targets(torch.cat([io.linprog(*f_learn(), eps=0.0000001).detach().t() for ui in u_train]), 'o', color=[0.1,0.7,0.0], markerfacecolor='white', markersize=10.0, markeredgewidth=1.5)\n",
    "\n",
    "lr = [10]\n",
    "max_steps = 20\n",
    "io.inverse_parametric_linprog(u_train, x_train, f_learn, lr=lr, max_steps=max_steps,\n",
    "                              callback=io.inverse_parametric_linprog_step_printer(),\n",
    "                              solver=io.custom_linprog(eps=0.001))\n",
    "\n",
    "# Plot c_learned\n",
    "f_learn.plot(color=[0, 0, 0.9], fig=fig, want_constraints=False)\n",
    "iop.plot_targets(torch.cat([io.linprog(*f_learn(), eps=0.0000001).detach().t() for ui in u_train]), 'o', color=[0.0,0.0,0.9], markerfacecolor='white', markersize=6.0, markeredgewidth=1.5)\n",
    "\n",
    "if FIGURE_SAVE_DIR:\n",
    "    plt.savefig(FIGURE_SAVE_DIR + '/deepinverse_fig1_cvector.pdf', bbox_inches='tight', dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 1B - \"learn c, A, b jointly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Figure1B_PLP(io.ParametricLP):\n",
    "    \n",
    "    def __init__(self, wc, wA, wb):\n",
    "        # wc should be angle of c\n",
    "        # wA should be coefficients for last three rows of A\n",
    "        # wb should be coefficients for last three rows of b\n",
    "        super().__init__(torch.cat([_.view(-1) for _ in as_tensor(wc, wA, wb)]))\n",
    "    \n",
    "    def generate(self, u, w):\n",
    "        wc = w[0:1].view(1, 1)\n",
    "        wA = w[1:7].view(3, 2)\n",
    "        wb = w[7:10].view(3, 1)\n",
    "        \n",
    "        c = [[torch.cos(wc)],\n",
    "             [torch.sin(wc)]]\n",
    "\n",
    "        A_ub = [[-1.0,  0.0],  # x0 >= 0\n",
    "                [ 0.0, -1.0],  # x1 >= 0\n",
    "                [ wA[0,0],  wA[0,1]],  # x0 <= 1\n",
    "                [ wA[1,0],  wA[1,1]],  # x1 <= 1\n",
    "                [ wA[2,0],  wA[2,1]]]  # x0 + x1 <= ...\n",
    "\n",
    "        b_ub = [[ 0.0 ],\n",
    "                [ 0.0 ],\n",
    "                [ wb[0,0] ],\n",
    "                [ wb[1,0] ],\n",
    "                [ wb[2,0]]]\n",
    "        \n",
    "        return c, A_ub, b_ub, None, None\n",
    "    \n",
    "    def __call__(self, u=None):\n",
    "        if u is None:\n",
    "            u = as_tensor([[0.0]])  # Dummy u, not used\n",
    "        return super().__call__(u)\n",
    "    \n",
    "    def plot(self, color='k', fig=None, linestyle=None, want_constraints=True):\n",
    "        with torch.no_grad():\n",
    "            # Set up the plot\n",
    "            if fig is None:\n",
    "                fig = plt.figure(dpi=100, figsize=(5, 5))\n",
    "                ax = fig.add_subplot(111)\n",
    "                ax.set_xlim(-0.35, 1.25)\n",
    "                ax.set_ylim(-0.35, 1.25)\n",
    "                \n",
    "                ax.set_aspect('equal', 'box')\n",
    "                ax.set_axis_off()\n",
    "                fig.tight_layout()\n",
    "            else:\n",
    "                ax = fig.gca()\n",
    "\n",
    "            # Plot each set of constraints\n",
    "            c, A_ub, b_ub, _, _ = as_numpy(*self())\n",
    "            iop.plot_linear_program(0.25*c,\n",
    "                                    A_ub if want_constraints else None,\n",
    "                                    b_ub if want_constraints else None,\n",
    "                                    color=color, linestyle=linestyle, cxy=(1.2, 1.0))\n",
    "            return fig, ax\n",
    "\n",
    "\n",
    "        \n",
    "f_true  = Figure1B_PLP(\n",
    "    wc=[np.pi*6/4-0.05],\n",
    "    wA=[[1.0, 0.0],\n",
    "        [0.0, 1.0],\n",
    "        [1.3, 1.0]],\n",
    "    wb=[[1.0],\n",
    "        [1.0],\n",
    "        [1.5]])\n",
    "\n",
    "import copy\n",
    "\n",
    "f_init  = Figure1B_PLP(\n",
    "    wc=[3.5],\n",
    "    wA=[[1.0, 0.0],\n",
    "        [0.0, 1.0],\n",
    "        [1.0, 1.5]],\n",
    "    wb=[[1.0],\n",
    "        [0.75],\n",
    "        [1.5]])\n",
    "\n",
    "u_train = io.tensor([[0.0]])\n",
    "x_train = torch.cat([io.linprog(*f_true(), eps=0.0000001).detach().t() for ui in u_train])\n",
    "\n",
    "# Custom learning rates to get the particular solution that looks interesting,\n",
    "# (Since learning constraints from single point is so under-determined, we can get lots of different\n",
    "#  solutions for constraints depending on initial c vector and these learning rates etc.)\n",
    "lr = [200,    # wc\n",
    "      .1, .1,  # wA\n",
    "      .1, .1,\n",
    "      .1, .1,\n",
    "      .1,     # wB\n",
    "      .1,\n",
    "      .1]\n",
    "max_steps = 50\n",
    "f_learn = copy.deepcopy(f_init)  # In order to plot f_init and f_learn separately and in reverse order, make a copy here.\n",
    "\n",
    "io.inverse_parametric_linprog(u_train, x_train, f_learn, lr=lr, max_steps=max_steps,\n",
    "                              callback=io.inverse_parametric_linprog_step_printer(),\n",
    "                              solver=io.custom_linprog(eps=0.001))\n",
    "\n",
    "# Do the actual plotting, finishing with f_true (black constraints on top)\n",
    "fig, ax = f_init.plot(color=[0.1, 0.7, 0.0])\n",
    "f_learn.plot(color=[0, 0, 0.9], fig=fig)\n",
    "f_true.plot(color='k', fig=fig)\n",
    "\n",
    "# Plot the target points\n",
    "iop.plot_targets(x_train, 'ok', markerfacecolor='white', markersize=14.0, markeredgewidth=1.5)\n",
    "iop.plot_targets(torch.cat([io.linprog(*f_init(), eps=0.0000001).detach().t() for ui in u_train]), 'o', color=[0.1,0.7,0.0], markerfacecolor='white', markersize=10.0, markeredgewidth=1.5)\n",
    "iop.plot_targets(torch.cat([io.linprog(*f_learn(), eps=0.0000001).detach().t() for ui in u_train]), 'o', color=[0.0,0.0,0.9], markerfacecolor='white', markersize=6.0, markeredgewidth=1.5)\n",
    "\n",
    "if FIGURE_SAVE_DIR:\n",
    "    plt.savefig(FIGURE_SAVE_DIR + '/deepinverse_fig1_constraints.pdf', bbox_inches='tight', dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 1C - \"parametric LP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Figure1C_PLP(io.ParametricLP):\n",
    "    \n",
    "    def generate(self, u, w):\n",
    "        w0, w1 = w\n",
    "\n",
    "        c = [[torch.cos(w0 + w1*u)],\n",
    "             [torch.sin(w0 + w1*u)]]\n",
    "\n",
    "        A_ub = [[-1.0,  0.0],\n",
    "                [ 0.0, -1.0],\n",
    "                [ w0,  1.0 + 1/3*w1*u]]\n",
    "\n",
    "        b_ub = [[ 0.0 + 0.2*w0*u],\n",
    "                [ 0.0 - 0.2*w1*u],\n",
    "                [ w0 + 0.1*u]]\n",
    "        \n",
    "        return c, A_ub, b_ub, None, None\n",
    "    \n",
    "    def plot(self, u, color='k', alpha=1.0, linestyle=None):\n",
    "        # Set up the plot\n",
    "        fig = plt.figure(dpi=100, figsize=(5, 5))\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.set_xlim(-0.35, 1.25)\n",
    "        ax.set_ylim(-0.35, 1.25)\n",
    "        ax.set_aspect('equal', 'box')\n",
    "        ax.set_axis_off()\n",
    "        fig.tight_layout()\n",
    "        \n",
    "        # Plot each set of constraints\n",
    "        for i, ui in enumerate(u):\n",
    "            # Alpha progresses from initial alpha to 1.0 as we go through the points\n",
    "            alpha_i = alpha + (1-alpha)*(i/(len(u)-1) if len(u) > 1 else 1)\n",
    "            \n",
    "            # Find the LP for this particular u\n",
    "            c, A_ub, b_ub, _, _ = as_numpy(*self(ui))\n",
    "            iop.plot_linear_program(0.25*c, A_ub, b_ub, color=color, alpha=alpha_i, linestyle=linestyle, cxy=(0.95, 0.95))\n",
    "\n",
    "        return fig, ax\n",
    "\n",
    "    \n",
    "###########################    \n",
    "        \n",
    "# These are the values of u that will be plotted and trained on\n",
    "u = io.tensor([[-1.5],\n",
    "               [-0.5],\n",
    "               [ 0.5],\n",
    "               [ 1.5]])\n",
    "        \n",
    "f_true = Figure1C_PLP([1.0, 1.0])\n",
    "\n",
    "u_train = u\n",
    "x_train = torch.cat([io.linprog(*f_true(ui), eps=0.0000001).detach().t() for ui in u_train])\n",
    "\n",
    "fig, ax = f_true.plot(u, color='k', alpha=0.25)\n",
    "iop.plot_targets(x_train, 'o', color='k', markerfacecolor='white', markersize=10.0, markeredgewidth=1.5, alpha=0.25)\n",
    "if FIGURE_SAVE_DIR:\n",
    "    plt.savefig(FIGURE_SAVE_DIR + '/deepinverse_fig1_parametric_1.pdf', bbox_inches='tight', dpi=100)\n",
    "\n",
    "\n",
    "f_learn = Figure1C_PLP([0.2, 0.4])\n",
    "fig, ax = f_learn.plot(u, color=[0.1, 0.7, 0.0], alpha=0.25)\n",
    "iop.plot_targets(torch.cat([io.linprog(*f_learn(ui), eps=0.0000001).detach().t() for ui in u_train]), 'o', markerfacecolor='white', markersize=8.0, markeredgewidth=1.5, color=[0.1, 0.7, 0.0], alpha=0.25)\n",
    "iop.plot_targets(x_train, 'o', color='k', markerfacecolor='none', markersize=14.0, markeredgewidth=1.5, alpha=0.25)\n",
    "if FIGURE_SAVE_DIR:\n",
    "    plt.savefig(FIGURE_SAVE_DIR + '/deepinverse_fig1_parametric_2.pdf', bbox_inches='tight', dpi=100)\n",
    "\n",
    "\n",
    "lr = [100, 100]\n",
    "max_steps = 20\n",
    "io.inverse_parametric_linprog(u_train, x_train, f_learn, lr=lr, max_steps=max_steps,\n",
    "                              callback=io.inverse_parametric_linprog_step_printer(),\n",
    "                              solver=io.custom_linprog(eps=0.00001))\n",
    "\n",
    "fig, ax = f_learn.plot(u, color=[0, 0, 0.9], alpha=0.25)\n",
    "iop.plot_targets(x_train, 'o', color='k', markerfacecolor='white', markersize=14.0, markeredgewidth=1.5, alpha=0.25)\n",
    "iop.plot_targets(torch.cat([io.linprog(*f_learn(ui), eps=0.0000001).detach().t() for ui in u_train]), 'o', markerfacecolor='white', markersize=6.0, markeredgewidth=1.5, color=[0.0, 0.0, 0.9], alpha=0.25)\n",
    "if FIGURE_SAVE_DIR:\n",
    "    plt.savefig(FIGURE_SAVE_DIR + '/deepinverse_fig1_parametric_3.pdf', bbox_inches='tight', dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
