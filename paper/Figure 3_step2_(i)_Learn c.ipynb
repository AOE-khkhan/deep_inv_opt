{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 3(i)\n",
    "\n",
    "This notebook contains three major parts: \n",
    "- I. initialize test instances based on baseline lps generated from previous notebook\n",
    "- II. Experiment (lean c using deep_inv_opt package)\n",
    "- III. Data Analysis (generating boxplot as Figure 3(i) in our paper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (C) to Yingcong Tan, Andrew Delong, Daria Terekhov. All Rights Reserved.\n",
    "\n",
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "from scipy.spatial import ConvexHull\n",
    "import matplotlib.pyplot as plt\n",
    "import deep_inv_opt as io\n",
    "import os\n",
    "from shutil import copyfile\n",
    "import time\n",
    "import torch\n",
    "\n",
    "def seed_random(seed=0):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# All generated files will be saved in the following directory\n",
    "PATH = \"C:/Users/Public/Downloads/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. initialize vertex taget for task of learning c\n",
    "Based on instance generated from **LP generator**, we sample initial c vectors (c_init) and vertex targets.\n",
    "\n",
    "- c_init is sampled through normal distribution, c_i = Norm(0,1)\n",
    "- vertex targets are randomly selected from all optimal solutions from the LP instances generated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_baselineLP(filename):\n",
    "    lines=[]\n",
    "    with open(filename, \"rt\") as fp:\n",
    "        for line in fp:\n",
    "            lines.append(line.rstrip('\\n')) \n",
    "    \n",
    "    m,n = np.fromstring(lines[0], dtype=int, sep=' ')\n",
    "    \n",
    "    temp = [lines[i+1: i+1+m] for i in range(len(lines)) if \"A_ub\" in lines[i]]\n",
    "    A_ub=np.zeros((m,n))\n",
    "    b_ub=np.zeros((m,1))\n",
    "    for j in range(m):\n",
    "        A_ub[j] = np.fromstring(temp[0][j], dtype=float, sep=' ')\n",
    "    \n",
    "    temp = [lines[i+1: i+1+m] for i in range(len(lines)) if \"b_ub\" in lines[i]]\n",
    "    for j in range(m):\n",
    "        b_ub[j] = np.fromstring(temp[0][j], dtype=float, sep=' ')\n",
    "        \n",
    "    temp = [lines[i] for i in range(len(lines)) if \"vertices\" in lines[i]]\n",
    "    num_vertices = int(temp[0].split()[0])\n",
    "\n",
    "    temp = [lines[i+1: i+1+num_vertices] for i in range(len(lines)) if \"vertices\" in lines[i]]\n",
    "    vertices = np.zeros((num_vertices,n))\n",
    "    for j in range(num_vertices):\n",
    "        vertices[j] = np.fromstring(temp[0][j], dtype=float, sep=' ')\n",
    "\n",
    "    return A_ub, b_ub, vertices\n",
    "\n",
    "\n",
    "\"\"\" uncomment the following lines to run a quick test of this cell  \"\"\"\n",
    "\n",
    "# print(\"===== Testing \\\"read_BaselineLP\\\"=====\")\n",
    "# nVar, nCons, ind_lp = 2,4,0\n",
    "# LPbaseline = PATH + \"Deep_Inv_Opt/LP baseline/n=%d,m=%d/%svar_LP%s.txt\"%(nVar, nCons, str(nVar).zfill(2),str(ind_lp+1).zfill(2))\n",
    "# A_ub, b_ub, vertices = read_baselineLP(LPbaseline)\n",
    "# print(A_ub, \"\\n\", b_ub, \"\\n\", vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Initialize_3a_instance(ind_lp, nCons, nVar):\n",
    "    def sample_c (num, n, dist_type):\n",
    "        if dist_type == \"uniform\":\n",
    "            temp = np.random.uniform(-1,1,(num,n))\n",
    "        elif dist_type == \"normal\":\n",
    "            mu = 0.0\n",
    "            sigma = 1.0\n",
    "            temp = np.random.normal(mu, sigma, (num,n))\n",
    "        return temp\n",
    "    \n",
    "    LPbaseline = PATH + \"Deep_Inv_Opt/LP baseline/n=%d,m=%d/%svar_LP%s.txt\"%(nVar, nCons, str(nVar).zfill(2),str(ind_lp+1).zfill(2))\n",
    "    _, _, opt_sol = read_baselineLP(LPbaseline)\n",
    "    vertex_ind = np.random.randint(0,len(opt_sol)) #randomly select target\n",
    "    c_init = sample_c(1, nVar, \"normal\")\n",
    "\n",
    "    directory = PATH + \"Deep_Inv_Opt/figure3_i/n=%d,m=%d/\"%(nVar, nCons)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    LP3a = directory + \"%svar_LP%s.txt\"%(str(nVar).zfill(2), str(ind_lp+1).zfill(2))\n",
    "\n",
    "    copyfile(LPbaseline, LP3a)\n",
    "    with open(LP3a, \"a\") as file:\n",
    "        # print LP size, m - # constrains, n - # # var\n",
    "        file.write(\"vertex target %d\\n\"%(vertex_ind+1))\n",
    "        np.savetxt(file, opt_sol[vertex_ind].reshape(1, nVar), fmt='%.6f')\n",
    "        file.write(\"\\nc_init\\n\")\n",
    "        np.savetxt(file, c_init.reshape(1, nVar), fmt='%.6f')\n",
    "        file.write(\"\\n\")    \n",
    "\n",
    "\"\"\" uncomment the following lines to run a quick test of this cell  \"\"\"\n",
    "# print(\"===== Testing \\\"Initialize_3a_instance\\\"=====\")\n",
    "# nVar, nCons, ind_lp = 2,4,0\n",
    "# Initialize_3a_instance(ind_lp, nCons, nVar)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the following cell to intialize instances for Figure3(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_random()\n",
    "\n",
    "_RANGE_CONS = [[4,  8,  16],\n",
    "               [20, 36, 80]]\n",
    "_RANGE_VAR = [2, 10]\n",
    "\n",
    "NUM_INS = 50\n",
    "\n",
    "for i, nVar in enumerate(_RANGE_VAR):\n",
    "    for nCons in _RANGE_CONS[i]:\n",
    "        for ind_lp in range(NUM_INS):\n",
    "            Initialize_3a_instance(ind_lp, nCons, nVar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Experiment -  Learn c using Deep_Inv_Opt package\n",
    "\n",
    "### Utility Functions\n",
    "- **ADG**: calcualte Error (Abs duality gap)\n",
    "- **MSE**: calculate Error (Square Error)\n",
    "- **Read_3aLP**: read test instance for experiment/data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ADG(c,x_predict, x_target):\n",
    "    c_vector = io.tensor(c).view(-1,1)\n",
    "    x_predict = io.tensor(x_predict).view(-1,1)\n",
    "    x_target = io.tensor(x_target).view(-1,1)\n",
    "    err = torch.abs(c_vector.t() @ (x_target - x_predict))\n",
    "    \n",
    "    return err.detach().numpy().ravel()\n",
    "\n",
    "def MSE(x1, x2):\n",
    "    x1 = io.tensor([x1]).view(-1,1)\n",
    "    x2 = io.tensor([x2]).view(-1,1)\n",
    "    err = torch.mean(torch.sum((x1 - x2)**2, 0))\n",
    "    \n",
    "    return err.detach().numpy().ravel()\n",
    "\n",
    "def Read_3aLP(filename):    \n",
    "    A_ub, b_ub, _ = read_baselineLP(filename)\n",
    "        \n",
    "    lines=[]    \n",
    "    with open(filename, \"rt\") as fp:\n",
    "        lines=fp.readlines()\n",
    "        for line in fp:\n",
    "            lines.append(line.rstrip('\\n')) \n",
    "\n",
    "    temp = [lines[j+1] for j in range(len(lines)) if \"c_init\" in lines[j]]\n",
    "    c_init = np.fromstring(temp[0], dtype=float, sep=' ') \n",
    "\n",
    "    temp = [lines[j+1] for j in range(len(lines)) if \"vertex target\" in lines[j]]\n",
    "    x_target = np.fromstring(temp[0], dtype=float, sep=' ') \n",
    "\n",
    "    return (A_ub, b_ub, x_target, c_init)\n",
    "\n",
    "\"\"\" uncomment the following lines to run a quick test of this cell  \"\"\"\n",
    "# print(\"===== Testing \\\"Read_3aLP\\\"=====\")\n",
    "# nVar, nCons, ind_lp = 10,20,0\n",
    "# filename = PATH + \"Deep_Inv_Opt/figure3_i/n=%d,m=%d/%svar_LP%s.txt\"%(nVar, nCons, str(nVar).zfill(2),str(ind_lp+1).zfill(2))\n",
    "# print(Read_3aLP(filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Hyperparameter Search\n",
    "Sample values of hyperparmeters from pre-defined sets, which are to be used in random hyper-parameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-defined set of hyperparameters\n",
    "_RANGE_T0 = [0.5, 1, 5, 10]\n",
    "_RANGE_MU= [1.5, 2, 5, 10, 20]\n",
    "_RANGE_LR_C = [1,10 ,100, 1000]\n",
    "_RANGE_EPS = [1e-5]\n",
    "\n",
    "def sample_hyperparam(filename, num_set = 20, print_hyperparam = True):\n",
    "    hyperParam = [[]]*num_set\n",
    "    for i in range(20):\n",
    "        mu = _RANGE_MU[np.random.randint(0, len(_RANGE_MU))]\n",
    "        t0 = _RANGE_T0[np.random.randint(0, len(_RANGE_T0))]\n",
    "        eps = _RANGE_EPS[np.random.randint(0, len(_RANGE_EPS))]\n",
    "        lr_c = _RANGE_LR_C[np.random.randint(0, len(_RANGE_LR_C))]\n",
    "        hyperParam[i] = (mu, t0, eps, lr_c)\n",
    "        if print_hyperparam:\n",
    "            print(\"hyperparam set %d\"%(i))\n",
    "            print(hyperParam[i])\n",
    "        with open(filename, 'w') as file:\n",
    "            for j in range(len(hyperParam)):\n",
    "                file.write(\"hyperParam%s: \"%(str(j+1).zfill(2)))\n",
    "                np.savetxt(file, np.mat(hyperParam[j]).ravel(), fmt='%.6f')\n",
    "            file.write(\"\\n\")\n",
    "\n",
    "def read_hyperParam(filename, num_set = 20):\n",
    "    with open(filename, 'rt') as file:\n",
    "        lines=file.readlines()\n",
    "        temp = [lines[i] for i in range(len(lines)) if \"hyperParam\" in lines[i]]\n",
    "        hyperParam = [[]]*num_set\n",
    "        for i in range(len(temp)):\n",
    "            te = temp[i]\n",
    "            te = te[14:]\n",
    "            te = te[:-2]\n",
    "            te = te.split(' ')\n",
    "            hyperParam[i] = [float(j) for j in te]\n",
    "\n",
    "    return hyperParam\n",
    "\n",
    "print(\"==== Sample Hyperparameters values for Random Hyperparameter Search====\")\n",
    "seed_random()\n",
    "filename = PATH + \"Deep_Inv_Opt/figure3_i/Hyper_Param.txt\"\n",
    "print_hyperparam = True # set this to False to disable the printing\n",
    "sample_hyperparam(filename)\n",
    "read_hyperParam(filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn with Deep_Inv_Opt package using random hyperparameter search\n",
    "\n",
    "#### Please Note, finishing the entire experiments (i.e., 6 * 50 instances for Training withboth of ADG and MSE) might take 1-2 days. You can see our paper for the experiment results directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_randomsearch(ind_lp, LPInstance, hyperParam):\n",
    "    #function to record result of each hyperparameter search\n",
    "    def record_result(filename, hyperpara, result):\n",
    "        loss, time, c_final, x_final = result\n",
    "        with open(filename, 'a') as file:\n",
    "            mu, t0, eps, lr_c = hyperParam[ind_search]\n",
    "            temp = (mu, t0, eps, lr_c, loss, time)\n",
    "            string = (\"hyperparam\"+str(ind_search+1).zfill(2)+\" \"+ str(temp) )\n",
    "            file.write(str(string))\n",
    "            file.write(\"\\n\")\n",
    "            file.write(\"c_final \")\n",
    "            np.savetxt(file, c.reshape(1,nVar), fmt='%.6f') \n",
    "            file.write(\"x_final \")\n",
    "            np.savetxt(file, x.reshape(1,nVar), fmt='%.6f')     \n",
    "\n",
    "    A_ub, b_ub, x_target, c_init = LPInstance\n",
    "    nCons,nVar = A_ub.shape\n",
    "    A_ub = io.tensor(A_ub)\n",
    "    b_ub = io.tensor(b_ub)  \n",
    "    c_init = io.tensor(c_init).view(-1,1)\n",
    "    x_target = io.tensor(x_target).view(-1,1)\n",
    "\n",
    "    print(\"||||| Ins %d (%d var, %d constraint), vertex target: \"\n",
    "          %(ind_lp+1, nVar, nCons))\n",
    "    print(\"||||| vertex target \",x_target.detach().numpy())\n",
    "    \n",
    "    for loss in [\"ADG\", \"MSE\"]:   \n",
    "        # record LP characteristics\n",
    "        _RESULT_FILE = PATH + 'Deep_Inv_Opt/figure3_i/EXP_%svar_%scon_%s.txt'%(str(nVar).zfill(2),str(nCons).zfill(2), loss)\n",
    "        with open(_RESULT_FILE, 'a') as file:\n",
    "            file.write( \"LP%s, %svar %scon:\\n\"\n",
    "                       %(str(ind_lp+1).zfill(2),str(nVar).zfill(2),str(nCons).zfill(2)))\n",
    "            file.write( \"Vertex \\n\" )\n",
    "            np.savetxt(file, x_target.detach().numpy().reshape(1,nVar), fmt='%.6f')\n",
    "            file.write(\"c_init: \")\n",
    "            np.savetxt(file, c_init.numpy().reshape(1,nVar), fmt='%.6f')                       \n",
    "\n",
    "        # initialize loss function\n",
    "        if loss ==\"ADG\":\n",
    "            loss_callback = io.abs_duality_gap\n",
    "            eps_decay = False\n",
    "\n",
    "        elif loss ==\"MSE\":\n",
    "            loss_callback = io.squared_error \n",
    "            eps_decay = True\n",
    "        \n",
    "        for ind_search in range(len(hyperParam)):\n",
    "            # initialize hyper parameters\n",
    "            mu, t0, eps, lr_c = hyperParam[ind_search]\n",
    "            print(\"loss func %s, HyperParam %d = (%.1f, %.1f, %.5f, %.1f\"\n",
    "                  %(loss, ind_search+1, mu, t0, eps, lr_c),\")\")\n",
    "            print(\"---- c_init \", c_init.numpy().ravel())\n",
    "            print(\"---- Hyper-Param Search %d / %d: \"%(ind_search+1, len(hyperParam)))\n",
    "            \n",
    "            solver = io.custom_linprog(t0 = t0, mu = mu, max_steps = 10000)\n",
    "\n",
    "            start_time = time.time()\n",
    "            try:\n",
    "                c_final, _, _, err, x_predict, init_err = io.inverse_linprog(x_target, \n",
    "                                                                            c_init,  A_ub, b_ub,\n",
    "                                                                            max_steps=200,\n",
    "                                                                            eps = eps, #defaul value for the end of eps_decay\n",
    "                                                                            eps_decay = eps_decay,\n",
    "                                                                            learn_rate_c=lr_c,\n",
    "                                                                            loss=loss_callback,\n",
    "                                                                            return_loss=True,\n",
    "                                                                            solver=solver)\n",
    "                runtime = time.time() - start_time\n",
    "\n",
    "                c = c_final.detach().numpy().ravel()\n",
    "                x = x_predict.detach().numpy().ravel()\n",
    "                l = err.detach().numpy().ravel()\n",
    "                t = runtime\n",
    "                \n",
    "                print(\"---- Final Loss\", l)\n",
    "\n",
    "                #record Hyper param values\n",
    "                result = (l[0], t, c, x)\n",
    "                record_result(_RESULT_FILE, hyperParam[ind_search], result)   \n",
    "                \n",
    "            except: # catch error and return failed hyperparam search\n",
    "                print(\"find an error, return failed hyperparam search\")\n",
    "                c = np.ones((c_init.shape))*999\n",
    "                x = np.ones((c_init.shape))*999              \n",
    "            \n",
    "                result = (999, 999, c, x)\n",
    "                record_result(_RESULT_FILE, hyperParam[ind_search], result) \n",
    "                pass\n",
    "            print()\n",
    "\n",
    "            \n",
    "RANGE_CONS = [[4,  8,  16],\n",
    "               [20, 36, 80]]\n",
    "RANGE_VAR = [2, 10]\n",
    "\n",
    "NUM_INS = 50\n",
    "\n",
    "for i, nVar in enumerate(RANGE_VAR):\n",
    "    for nCons in RANGE_CONS[i]:\n",
    "        for ind_lp in range(NUM_INS):\n",
    "            filename = PATH + \"Deep_Inv_Opt/figure3_i/n=%d,m=%d/%svar_LP%s.txt\"%(nVar, nCons, str(nVar).zfill(2),str(ind_lp+1).zfill(2))\n",
    "            LPInstance = Read_3aLP(filename)\n",
    "            hyperParam = read_hyperParam(PATH + 'Deep_Inv_Opt/figure3_i/Hyper_Param.txt')\n",
    "            exp_randomsearch(ind_lp, LPInstance, hyperParam)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Data Analysis\n",
    "\n",
    "### Unility Function\n",
    "- **read_finalresult**: read result from data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_finalresult(num_lp, nCons, nVar, loss):\n",
    "    print(\"\\tloss = \", loss)\n",
    "    c_init = np.zeros((num_lp, nVar))\n",
    "\n",
    "    # read c_init and LP ins\n",
    "    for ind_lp in range(num_lp):\n",
    "        filename = PATH + \"Deep_Inv_Opt/figure3_i/n=%d,m=%d/%svar_LP%s.txt\"%(nVar, nCons, str(nVar).zfill(2),str(ind_lp+1).zfill(2))\n",
    "        A, b, opt_sol, c = Read_3aLP(filename)\n",
    "        c_init[ind_lp] = c\n",
    "\n",
    "    # read x_target\n",
    "    x_target = np.zeros((num_lp, nVar))\n",
    "    result = []\n",
    "    c_final = []\n",
    "    x_final = []\n",
    "\n",
    "    with open(PATH + 'Deep_Inv_Opt/figure3_i/FinalExp _%svar_%scon_%s.txt'\n",
    "              %(str(nVar).zfill(2),str(nCons).zfill(2), loss), 'rt') as file:\n",
    "        lines=file.readlines()\n",
    "        temp = [lines[i+1] for i in range(len(lines)) if \"Vertex\" in lines[i]]\n",
    "        for i in range((len(temp))):\n",
    "            te =temp[i]\n",
    "            te = te.split(' ')\n",
    "            te = [float(d) for d in te]\n",
    "            x_target[i] = te\n",
    "        #read exp results of every trail (mu, to, eps, lr_c, err, runtime)\n",
    "        temp = [lines[i] for i in range(len(lines)) if \"hyperparam\" in lines[i]]\n",
    "        for i in range(len(temp)):\n",
    "            te = temp[i]\n",
    "            te = te[14:]\n",
    "            te = te[:-2]\n",
    "\n",
    "            te = te.split(',')\n",
    "            te = [float(d) for d in te]\n",
    "            result.append(te)\n",
    "        result= np.mat(result)\n",
    "        #from result find the index of the best trail for each LP ins\n",
    "        best_ind = []\n",
    "        for i in range(num_lp):\n",
    "            best_ind.append(int ( i*20 + np.argmin(result[i*20:(i+1)*20,-2])))\n",
    "        best_ind = np.array(best_ind)\n",
    "        # read c_final for every trail\n",
    "        temp = [lines[i] for i in range(len(lines)) if \"c_final\" in lines[i]]\n",
    "        for i in range(len(temp)):\n",
    "            te = temp[i]\n",
    "            te = te[8:]                \n",
    "            te = te.split(' ')\n",
    "            te = [float(d) for d in te]\n",
    "            c_final.append(te)\n",
    "        c_final= np.mat(c_final)\n",
    "        \n",
    "        # read x_final for every trail\n",
    "        temp = [lines[i] for i in range(len(lines)) if \"x_final\" in lines[i]]\n",
    "        for i in range(len(temp)):\n",
    "            te = temp[i]\n",
    "            te = te[8:]                \n",
    "            te = te.split(' ')\n",
    "            te = [float(d) for d in te]\n",
    "            x_final.append(te)\n",
    "        x_final= np.mat(x_final)\n",
    "        \n",
    "    return result, c_init, c_final, best_ind, x_target, x_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect experiment results using the read_finalresult function\n",
    "- collect final error (using ADG and MSE functions defined before)\n",
    "- collect initial c and x to computer initial error (using ADG and MSE functions defined before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Collect_Err(num_lp,  nVar, num_constraints,loss):\n",
    "    err_final = np.zeros((num_lp,len(num_constraints)))\n",
    "    err_init = np.zeros((num_lp, len(num_constraints)))\n",
    "    for j,nCons in enumerate (num_constraints): \n",
    "        print(\"LPs with %dVar, %dCons\"%(nVar,nCons))\n",
    "        result, c_init, c_final, best_ind, x_target, x_final = read_finalresult(num_lp, nCons, nVar, loss)\n",
    "        err = result[best_ind,-2]\n",
    "        err_final[:,j] = np.array(err).ravel()\n",
    "        \n",
    "        for ind_lp in range(num_lp):\n",
    "            filename = PATH + \"Deep_Inv_Opt/figure3_i/n=%d,m=%d/%svar_LP%s.txt\"%(nVar, nCons, str(nVar).zfill(2),str(ind_lp+1).zfill(2))\n",
    "            A, b, _, _ = Read_3aLP(filename)\n",
    "            \n",
    "            A_ub = io.tensor(A)\n",
    "            b_ub = io.tensor(b).view(-1,1)\n",
    "            c_vector = io.tensor(c_init[ind_lp]).view(-1,1)\n",
    "            c_vector/=sum(abs(c_vector))\n",
    "            x_predict = io.linprog(c_vector, A_ub, b_ub, eps = 1e-6).detach().numpy()\n",
    "            if loss == \"ADG\":            \n",
    "                err_init[ind_lp, j] = ADG( c_vector.detach().numpy(), \n",
    "                                        x_predict, x_target[ind_lp])\n",
    "            elif loss == \"MSE\":            \n",
    "                err_init[ind_lp, j] = MSE(x_predict, x_target[ind_lp])\n",
    "    return err_init, err_final\n",
    "\n",
    "num_lp = 50\n",
    "RANGE_CONS = [[4,  8,  16],\n",
    "               [20, 36, 80]]\n",
    "\n",
    "ADG02_init, ADG02_final = Collect_Err(num_lp, 2, RANGE_CONS[0], \"ADG\")\n",
    "\n",
    "ADG10_init, ADG10_final = Collect_Err(num_lp, 10, RANGE_CONS[1], \"ADG\")\n",
    "\n",
    "MSE02_init, MSE02_final = Collect_Err(num_lp, 2, RANGE_CONS[0], \"MSE\")\n",
    "\n",
    "MSE10_init, MSE10_final = Collect_Err(num_lp, 10, RANGE_CONS[1], \"MSE\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create boxplot using the collected data from the previous cell\n",
    "\n",
    "**Note, the final boxplots might not look identical to what we presented in the paper due to the randomization in baseline LP generation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_ERR = (MSE02_init, MSE02_final, MSE10_init, MSE10_final)\n",
    "ADG_ERR = (ADG02_init, ADG02_final, ADG10_init, ADG10_final )\n",
    "\n",
    "def final_plot(err_data, loss):\n",
    "    init02, final02, init10, final10 = err_data\n",
    "    print(final02.shape)\n",
    "        \n",
    "    data02 = init02\n",
    "    for i in range(3):\n",
    "        data02 = np.insert(data02, i*2+1, final02[:,i], axis=1)\n",
    "    data10 = init10\n",
    "    for i in range(3):\n",
    "        data10 = np.insert(data10, i*2+1, final10[:,i], axis=1)\n",
    "        \n",
    "        \n",
    "    data_ = np.column_stack((data02,data10))\n",
    "\n",
    "    if _LOSS == \"ADG\":\n",
    "        data_ [data_<1e-8]=1e-8\n",
    "    elif _LOSS == \"MSE\":\n",
    "        data_ [data_<1e-10]=1e-10\n",
    "    \n",
    "    return data_\n",
    "\n",
    "for _LOSS in [\"MSE\", \"ADG\"]:\n",
    "    if _LOSS == \"ADG\":\n",
    "        data = final_plot(ADG_ERR, _LOSS)\n",
    "        fig = plt.figure(figsize=(10,10))\n",
    "        ax = fig.add_subplot(111)\n",
    "        plt.ylim((1e-9,1e1))\n",
    "    elif _LOSS == \"MSE\":\n",
    "        data = final_plot(MSE_ERR, _LOSS)\n",
    "        fig = plt.figure(figsize=(10,10))\n",
    "        ax = fig.add_subplot(111)\n",
    "        plt.ylim((1e-11,1e2))\n",
    "\n",
    "    _, nbox = data.shape    \n",
    "\n",
    "    ind_init = np.arange(0,nbox,2)\n",
    "    ind_final = np.arange(1,nbox,2)\n",
    "\n",
    "    y_init = data[:, ind_init]\n",
    "    x_init = np.random.uniform(1-.15, 1+0.15, size=len(data[:, ind_init]))\n",
    "    y_final = data[:, ind_final]\n",
    "    x_final = np.random.uniform(2-.15, 2+0.15, size=len(data[:, ind_final]))\n",
    "    for i in np.arange(2, nbox,2):\n",
    "        min = i+1-0.15\n",
    "        max = i+1+0.15\n",
    "        x_init = np.column_stack((x_init, np.random.uniform(i+1-.15, i+1+0.15, \n",
    "                                                            size=len(data[:, i]))))\n",
    "    for i in np.arange(3, nbox,2):\n",
    "        min = i+1-0.15\n",
    "        max = i+1+0.15\n",
    "        x_final = np.column_stack((x_final, np.random.uniform(i+1-.15, i+1+0.15, \n",
    "                                                              size=len(data[:, i]))))\n",
    "    ax.boxplot(data,sym='',medianprops =dict(color='black'))\n",
    "    ax.plot([], 'go',markerfacecolor='w', alpha=0.8, label = 'init_loss vertex target')  \n",
    "    ax.plot([], 'bo',markerfacecolor='w', alpha=0.8, label = 'final_loss vertex target') \n",
    "\n",
    "    for i in range(nbox//2):\n",
    "        ax.plot(x_init[:, i], y_init[:, i], 'go',markerfacecolor='w', alpha=0.8) \n",
    "\n",
    "    for i in range(nbox//2):\n",
    "        ax.plot(x_final[:, i], y_final[:, i], 'bo',markerfacecolor='w', alpha=0.8) \n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1),\n",
    "              fontsize = 12, ncol=3)\n",
    "\n",
    "    \n",
    "    plt.xticks([], [])\n",
    "    plt.yscale(\"log\")\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.savefig(PATH+\"Deep_Inv_Opt/deepinverse_figure3_i_%s.pdf\"%_LOSS, frameon = True, bbox_inches='tight', dpi=100)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
